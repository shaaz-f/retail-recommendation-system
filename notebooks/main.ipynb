{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c566a77",
   "metadata": {},
   "source": [
    "# retail-recommendation-system\n",
    "\n",
    "This project implements a product recommendation system using PyTorch. The goal is to train a model that can recommend relevant products to users based on their past behavior, including clicks, cart additions, and purchases.\n",
    "\n",
    "I am using Neural Collaborative Filtering in order to learn nonlinear relationships while also understanding the ins and outs of PyTorch.\n",
    "\n",
    "## Features\n",
    "Literally just preprocessing, building, training, and using the model for predictions. Also evaluation metrics.\n",
    "\n",
    "## Dataset\n",
    "https://www.kaggle.com/datasets/retailrocket/ecommerce-dataset/data\n",
    "\n",
    "## Tech Stack\n",
    "- Python 3\n",
    "- VSCode\n",
    "- PyTorch, pandas, numpy, scikit-learn\n",
    "- Jupyter Notebook\n",
    "\n",
    "## The Process\n",
    "- The goal of this project was primarily to learn PyTorch in a more interactive way, as I have not used it to it's fullest up to this point (mostly boilerplate code).\n",
    "- I didn't want the project itself to be too easy, and so I decided to implement something I haven't even learned the theory about up to this point in recommendation systems.\n",
    "- At the end, I wanted to implement a Neural Collaborative Filtering model to make use of neural networks in recommender systems.\n",
    "- I ran into many problems including simple overfitting but also just not knowing what I was doing, but through a few resources and some trial and error, I was able to figure it out.\n",
    "\n",
    "*Keep in mind, there is always room for improvement, but I consider this a success given my new found understanding of PyTorch*\n",
    "\n",
    "## How to use\n",
    "1. Pull the git or download the files.\n",
    "2. Download the dataset to the same directory under data/\n",
    "3. Pip install the requirements.txt to your env.\n",
    "4. Run the notebook.\n",
    "\n",
    "## What's next?\n",
    "- Fix up the evaluations.\n",
    "- Log more stuff.\n",
    "- Spend some time fine-tuning hyperparameters for better convergence.\n",
    "\n",
    "## References\n",
    "- https://arxiv.org/abs/1708.05031\n",
    "- https://github.com/yihong-chen/neural-collaborative-filtering/tree/master\n",
    "- https://youtu.be/O4lk9Lw7lS0?si=T4tDJ1xz1I9IuCvv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8b8761",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6d84ab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4264a7a",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f4bd4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "events = pd.read_csv('../data/events.csv')\n",
    "prop1 = pd.read_csv('../data/item_properties_part1.csv')\n",
    "prop2 = pd.read_csv('../data/item_properties_part2.csv')\n",
    "\n",
    "properties = pd.concat([prop1, prop2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71f018b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>itemid</th>\n",
       "      <th>property</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1435460400000</td>\n",
       "      <td>460429</td>\n",
       "      <td>categoryid</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1441508400000</td>\n",
       "      <td>206783</td>\n",
       "      <td>888</td>\n",
       "      <td>1116713 960601 n277.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439089200000</td>\n",
       "      <td>395014</td>\n",
       "      <td>400</td>\n",
       "      <td>n552.000 639502 n720.000 424566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1431226800000</td>\n",
       "      <td>59481</td>\n",
       "      <td>790</td>\n",
       "      <td>n15360.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1431831600000</td>\n",
       "      <td>156781</td>\n",
       "      <td>917</td>\n",
       "      <td>828513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp  itemid    property                            value\n",
       "0  1435460400000  460429  categoryid                             1338\n",
       "1  1441508400000  206783         888          1116713 960601 n277.200\n",
       "2  1439089200000  395014         400  n552.000 639502 n720.000 424566\n",
       "3  1431226800000   59481         790                       n15360.000\n",
       "4  1431831600000  156781         917                           828513"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b144eb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>event</th>\n",
       "      <th>itemid</th>\n",
       "      <th>transactionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1433221332117</td>\n",
       "      <td>257597</td>\n",
       "      <td>view</td>\n",
       "      <td>355908</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1433224214164</td>\n",
       "      <td>992329</td>\n",
       "      <td>view</td>\n",
       "      <td>248676</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1433221999827</td>\n",
       "      <td>111016</td>\n",
       "      <td>view</td>\n",
       "      <td>318965</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1433221955914</td>\n",
       "      <td>483717</td>\n",
       "      <td>view</td>\n",
       "      <td>253185</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1433221337106</td>\n",
       "      <td>951259</td>\n",
       "      <td>view</td>\n",
       "      <td>367447</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp  visitorid event  itemid  transactionid\n",
       "0  1433221332117     257597  view  355908            NaN\n",
       "1  1433224214164     992329  view  248676            NaN\n",
       "2  1433221999827     111016  view  318965            NaN\n",
       "3  1433221955914     483717  view  253185            NaN\n",
       "4  1433221337106     951259  view  367447            NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#events.sort_values(by=['visitorid', 'itemid'], inplace=True)\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab70c985",
   "metadata": {},
   "source": [
    "Properties is not going to be too useful to us, but we can incorporate it later in a content-based filtering system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ced6b04",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c33301",
   "metadata": {},
   "source": [
    "Now we are trying to make a data matrix that has view counts, binary added-to-cart, and binary transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0fcdaf24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitorid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>view</th>\n",
       "      <th>cart</th>\n",
       "      <th>transaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>67045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>285930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>357564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>72028</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>216305</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visitorid  itemid  view  cart  transaction\n",
       "0          0   67045   1.0   0.0          0.0\n",
       "1          0  285930   1.0   0.0          0.0\n",
       "2          0  357564   1.0   0.0          0.0\n",
       "3          1   72028   1.0   0.0          0.0\n",
       "4          2  216305   2.0   0.0          0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "views = events[events['event'] == 'view'][['visitorid', 'itemid']].copy()\n",
    "views = views.groupby(['visitorid', 'itemid']).size().reset_index(name='view')\n",
    "\n",
    "carts = events[events['event'] == 'addtocart'][['visitorid', 'itemid']].copy()\n",
    "carts['cart'] = 1\n",
    "\n",
    "transactions = events[events['event'] == 'transaction'][['visitorid', 'itemid']].copy()\n",
    "transactions['transaction'] = 1\n",
    "\n",
    "merged = pd.merge(views, carts, on=['visitorid', 'itemid'], how='outer')\n",
    "merged = pd.merge(merged, transactions, on=['visitorid', 'itemid'], how='outer')\n",
    "\n",
    "merged.fillna(0, inplace=True)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d053dc3",
   "metadata": {},
   "source": [
    "For the scoring, decided to include a bit of everything for targets. Logging the view count, capping at 5, 5 for cart, and 10 for purchasing.\n",
    "It is then also min-max normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cd59e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitorid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>view</th>\n",
       "      <th>cart</th>\n",
       "      <th>transaction</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>67045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>285930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>357564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>72028</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>216305</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visitorid  itemid  view  cart  transaction     score\n",
       "0          0   67045   1.0   0.0          0.0  0.693147\n",
       "1          0  285930   1.0   0.0          0.0  0.693147\n",
       "2          0  357564   1.0   0.0          0.0  0.693147\n",
       "3          1   72028   1.0   0.0          0.0  0.693147\n",
       "4          2  216305   2.0   0.0          0.0  1.098612"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = merged.copy()\n",
    "data['score'] = np.minimum(np.log(1 + data['view']), 5) + 5*data['cart'] + 10*data['transaction']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ed7e5",
   "metadata": {},
   "source": [
    "Boom. I think we need to map everything to unique IDs now for the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b8d0a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users: 1407580\n",
      "Unique items: 235061\n"
     ]
    }
   ],
   "source": [
    "num_users = data['visitorid'].nunique()\n",
    "num_items = data['itemid'].nunique()\n",
    "\n",
    "print(f\"Unique users: {num_users}\")\n",
    "print(f\"Unique items: {num_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2f91081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitorid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>view</th>\n",
       "      <th>cart</th>\n",
       "      <th>transaction</th>\n",
       "      <th>score</th>\n",
       "      <th>usermap</th>\n",
       "      <th>itemmap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>67045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>285930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>357564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>72028</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>216305</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021001</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visitorid  itemid  view  cart  transaction     score  usermap  itemmap\n",
       "0          0   67045   1.0   0.0          0.0  0.000000        0        0\n",
       "1          0  285930   1.0   0.0          0.0  0.000000        0        1\n",
       "2          0  357564   1.0   0.0          0.0  0.000000        0        2\n",
       "3          1   72028   1.0   0.0          0.0  0.000000        1        3\n",
       "4          2  216305   2.0   0.0          0.0  0.021001        2        4"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_users = data.visitorid.unique()\n",
    "user_to_index = {old: new for new,old in enumerate(unique_users)}\n",
    "\n",
    "unique_products = data.itemid.unique()\n",
    "product_to_index = {old: new for new,old in enumerate(unique_products)}\n",
    "\n",
    "data['usermap'] = data['visitorid'].map(user_to_index)\n",
    "data['itemmap'] = data['itemid'].map(product_to_index)\n",
    "\n",
    "# Min-max normalization\n",
    "min_score = data['score'].min()\n",
    "max_score = data['score'].max()\n",
    "\n",
    "data['score'] = (data['score'] - min_score) / (max_score - min_score)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f189a1b",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb0e531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCFDataset(Dataset):\n",
    "    def __init__(self, users, items, score):\n",
    "        self.users = users\n",
    "        self.items = items\n",
    "        self.score = score\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        users = self.users[idx]\n",
    "        items = self.items[idx]\n",
    "        score = self.score[idx]\n",
    "        return {\n",
    "            \"users\": torch.tensor(users, dtype = torch.long),\n",
    "            \"items\": torch.tensor(items, dtype = torch.long),\n",
    "            \"score\": torch.tensor(score, dtype = torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c44c3a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCFModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(NCFModel, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.num_users = config['num_users']\n",
    "        self.num_items = config['num_items']\n",
    "        self.latent_dim_mf = config['latent_dim_mf']\n",
    "        self.latent_dim_mlp = config['latent_dim_mlp']\n",
    "\n",
    "        # Matrix Factorization\n",
    "        self.user_embedding_mf = torch.nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.latent_dim_mf)\n",
    "        self.item_embedding_mf = torch.nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.latent_dim_mf)\n",
    "\n",
    "        # Multilayer Perceptron\n",
    "        self.user_embedding_mlp = torch.nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.latent_dim_mlp)\n",
    "        self.item_embedding_mlp = torch.nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.latent_dim_mlp)\n",
    "\n",
    "        self.fc_layers = torch.nn.ModuleList()\n",
    "        for idx, (in_size, out_size) in enumerate(zip(config['layers'][:-1], config['layers'][1:])):\n",
    "            self.fc_layers.append(torch.nn.Linear(in_size, out_size))\n",
    "        \n",
    "        self.logits = torch.nn.Linear(in_features=config['layers'][-1] + config['latent_dim_mf'], out_features=1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, user_i, item_i):\n",
    "        user_embedding_mlp = self.user_embedding_mlp(user_i)\n",
    "        item_embedding_mlp = self.item_embedding_mlp(item_i)\n",
    "        user_embedding_mf = self.user_embedding_mf(user_i)\n",
    "        item_embedding_mf = self.item_embedding_mf(item_i)\n",
    "\n",
    "        # MF part\n",
    "        mf_vector = torch.mul(user_embedding_mf, item_embedding_mf)\n",
    "        mf_vector = torch.nn.Dropout(self.config['dropout_rate_mf'])(mf_vector)\n",
    "\n",
    "        # MLP part\n",
    "        mlp_vector = torch.cat([user_embedding_mlp, item_embedding_mlp], dim=-1)\n",
    "\n",
    "        for idx, _ in enumerate(range(len(self.fc_layers))):\n",
    "            mlp_vector = self.fc_layers[idx](mlp_vector)\n",
    "            mlp_vector = torch.nn.ReLU()(mlp_vector) # Activation\n",
    "        mlp_vector = torch.nn.Dropout(self.config['dropout_rate_mlp'])(mlp_vector)\n",
    "\n",
    "        # Combining results\n",
    "        vector = torch.cat([mlp_vector, mf_vector], dim=-1)\n",
    "        output = self.logits(vector)\n",
    "        output = self.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a70e1cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available()else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "803f4d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['usermap', 'itemmap', 'score']]\n",
    "\n",
    "# First split: train+val and test\n",
    "df_temp, df_test = train_test_split(\n",
    "    df, test_size=0.1, random_state=18\n",
    ")\n",
    "\n",
    "# Second split: train and val from the remaining 90%\n",
    "df_train, df_val = train_test_split(\n",
    "    df_temp, test_size=0.1, random_state=18\n",
    ")\n",
    "\n",
    "train_dataset = NCFDataset(list(df_train['usermap']), list(df_train['itemmap']), list(df_train['score']))\n",
    "val_dataset = NCFDataset(list(df_val['usermap']), list(df_val['itemmap']), list(df_val['score']))\n",
    "test_dataset = NCFDataset(list(df_test['usermap']), list(df_test['itemmap']), list(df_test['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3fc191a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 37.0387 | Validation Loss = 0.8877\n",
      "Epoch 2: Loss = 7.8203 | Validation Loss = 0.8747\n",
      "Epoch 3: Loss = 7.7610 | Validation Loss = 0.8695\n",
      "Epoch 4: Loss = 7.7061 | Validation Loss = 0.8624\n",
      "Epoch 5: Loss = 7.6226 | Validation Loss = 0.8488\n",
      "Epoch 6: Loss = 7.4600 | Validation Loss = 0.8348\n",
      "Epoch 7: Loss = 7.2928 | Validation Loss = 0.8152\n",
      "Epoch 8: Loss = 7.1066 | Validation Loss = 0.7985\n",
      "Epoch 9: Loss = 6.9122 | Validation Loss = 0.7759\n",
      "Epoch 10: Loss = 6.6322 | Validation Loss = 0.7529\n",
      "Epoch 11: Loss = 6.2921 | Validation Loss = 0.7384\n",
      "Epoch 12: Loss = 5.9786 | Validation Loss = 0.7299\n",
      "Epoch 13: Loss = 5.7139 | Validation Loss = 0.7267\n",
      "Epoch 14: Loss = 5.4594 | Validation Loss = 0.7290\n",
      "Epoch 15: Loss = 5.1795 | Validation Loss = 0.7266\n",
      "Epoch 16: Loss = 4.9038 | Validation Loss = 0.7271\n",
      "Epoch 17: Loss = 4.6567 | Validation Loss = 0.7320\n",
      "Epoch 18: Loss = 4.4283 | Validation Loss = 0.7327\n",
      "Epoch 19: Loss = 4.1659 | Validation Loss = 0.7413\n",
      "Epoch 20: Loss = 3.8840 | Validation Loss = 0.7481\n",
      "Epoch 21: Loss = 3.6216 | Validation Loss = 0.7393\n",
      "Epoch 22: Loss = 3.4176 | Validation Loss = 0.7489\n",
      "Epoch 23: Loss = 3.2753 | Validation Loss = 0.7506\n",
      "Epoch 24: Loss = 3.1414 | Validation Loss = 0.7608\n",
      "Epoch 25: Loss = 3.0418 | Validation Loss = 0.7571\n",
      "Epoch 26: Loss = 2.9461 | Validation Loss = 0.7578\n",
      "Epoch 27: Loss = 2.8789 | Validation Loss = 0.7597\n",
      "Epoch 28: Loss = 2.8267 | Validation Loss = 0.7606\n",
      "Epoch 29: Loss = 2.7529 | Validation Loss = 0.7558\n",
      "Epoch 30: Loss = 2.7238 | Validation Loss = 0.7610\n",
      "Epoch 31: Loss = 2.6702 | Validation Loss = 0.7672\n",
      "Epoch 32: Loss = 2.6474 | Validation Loss = 0.7575\n",
      "Epoch 33: Loss = 2.5864 | Validation Loss = 0.7488\n",
      "Epoch 34: Loss = 2.5595 | Validation Loss = 0.7693\n",
      "Epoch 35: Loss = 2.5191 | Validation Loss = 0.7541\n",
      "Epoch 36: Loss = 2.4908 | Validation Loss = 0.7407\n",
      "Epoch 37: Loss = 2.4530 | Validation Loss = 0.7411\n",
      "Epoch 38: Loss = 2.4214 | Validation Loss = 0.7620\n",
      "Epoch 39: Loss = 2.4087 | Validation Loss = 0.7640\n",
      "Epoch 40: Loss = 2.3761 | Validation Loss = 0.7535\n",
      "Epoch 41: Loss = 2.3504 | Validation Loss = 0.7396\n",
      "Epoch 42: Loss = 2.3178 | Validation Loss = 0.7473\n",
      "Epoch 43: Loss = 2.3045 | Validation Loss = 0.7517\n",
      "Epoch 44: Loss = 2.2754 | Validation Loss = 0.7480\n",
      "Epoch 45: Loss = 2.2590 | Validation Loss = 0.7432\n",
      "Epoch 46: Loss = 2.2309 | Validation Loss = 0.7537\n",
      "Epoch 47: Loss = 2.2265 | Validation Loss = 0.7711\n",
      "Epoch 48: Loss = 2.2059 | Validation Loss = 0.7374\n",
      "Epoch 49: Loss = 2.1954 | Validation Loss = 0.7218\n",
      "Epoch 50: Loss = 2.1762 | Validation Loss = 0.7458\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "config = {\n",
    "    'num_epoch': 50,\n",
    "    'batch_size': 2048,\n",
    "    'num_users': num_users,\n",
    "    'num_items': num_items,\n",
    "    'latent_dim_mf': 32,\n",
    "    'latent_dim_mlp': 32,\n",
    "    'layers': [64, 32, 16],\n",
    "    'dropout_rate_mf': 0.1,\n",
    "    'dropout_rate_mlp': 0.1,\n",
    "    'decay': 1e-5,\n",
    "    'learning_rate': 0.0005\n",
    "}\n",
    "\n",
    "# Model\n",
    "recc_model = NCFModel(config).to(device)\n",
    "optimizer = optim.Adam(recc_model.parameters(), lr=config['learning_rate'], weight_decay=config['decay'])\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "# Training\n",
    "losses = []\n",
    "recc_model.train()\n",
    "for e in range(config['num_epoch']):\n",
    "    epoch_loss = 0\n",
    "    for idx, train_data in enumerate(train_loader):\n",
    "        output = recc_model(train_data['users'].to(device), train_data['items'].to(device)).squeeze()\n",
    "        score = (train_data['score'].to(torch.float32).to(device))\n",
    "        loss = loss_fn(output, score)\n",
    "        #print(f\"Output min/max: {output.min().item():.4f}/{output.max().item():.4f}\")\n",
    "        #print(f\"Score min/max: {score.min().item():.4f}/{score.max().item():.4f}\")\n",
    "        #print(output, score)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    recc_model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_data in val_loader:\n",
    "            output = recc_model(val_data['users'].to(device), val_data['items'].to(device)).squeeze()\n",
    "            score = val_data['score'].to(torch.float32).to(device)\n",
    "            loss = loss_fn(output, score)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    losses.append(epoch_loss)\n",
    "    print(f\"Epoch {e+1}: Loss = {epoch_loss:.4f} | Validation Loss = {val_loss:.4f}\")\n",
    "    recc_model.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0e2661",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Note; using AI for this, will change in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f0fa115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(r, k):\n",
    "    r = np.asarray(r, dtype=np.float32)[:k]\n",
    "    return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "\n",
    "def ndcg_at_k(r, k):\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k)\n",
    "    if not dcg_max:\n",
    "        return 0.0\n",
    "    return dcg_at_k(r, k) / dcg_max\n",
    "\n",
    "def precision_at_k(r, k):\n",
    "    r = np.asarray(r)[:k]\n",
    "    return np.mean(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "065ebfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_df, all_item_ids, K=10, device='cpu'):\n",
    "    model.eval()\n",
    "    user_item_scores = defaultdict(list)\n",
    "    \n",
    "    # Group test data by user\n",
    "    grouped = test_df.groupby('usermap')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for user, group in grouped:\n",
    "            true_items = set(group['itemmap'].values)\n",
    "            \n",
    "            # Predict scores for all items\n",
    "            user_tensor = torch.LongTensor([user] * len(all_item_ids)).to(device)\n",
    "            item_tensor = torch.LongTensor(all_item_ids).to(device)\n",
    "            \n",
    "            scores = model(user_tensor, item_tensor).squeeze().cpu().numpy()\n",
    "            ranked_items = np.argsort(scores)[::-1]  # Descending order\n",
    "            \n",
    "            recommended = [all_item_ids[i] for i in ranked_items[:K]]\n",
    "            rel = [1 if item in true_items else 0 for item in recommended]\n",
    "            \n",
    "            user_item_scores['ndcg'].append(ndcg_at_k(rel, K))\n",
    "            user_item_scores['precision'].append(precision_at_k(rel, K))\n",
    "\n",
    "    avg_ndcg = np.mean(user_item_scores['ndcg'])\n",
    "    avg_precision = np.mean(user_item_scores['precision'])\n",
    "    \n",
    "    print(f\"NDCG@{K}: {avg_ndcg:.4f}\")\n",
    "    print(f\"Precision@{K}: {avg_precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6dd52a9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m all_item_ids = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(config[\u001b[33m'\u001b[39m\u001b[33mnum_items\u001b[39m\u001b[33m'\u001b[39m]))\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# test_df = original test split\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecc_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_item_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, test_df, all_item_ids, K, device)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Predict scores for all items\u001b[39;00m\n\u001b[32m     13\u001b[39m user_tensor = torch.LongTensor([user] * \u001b[38;5;28mlen\u001b[39m(all_item_ids)).to(device)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m item_tensor = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLongTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_item_ids\u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m     16\u001b[39m scores = model(user_tensor, item_tensor).squeeze().cpu().numpy()\n\u001b[32m     17\u001b[39m ranked_items = np.argsort(scores)[::-\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# Descending order\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "all_item_ids = list(range(config['num_items']))\n",
    "\n",
    "# test_df = original test split\n",
    "evaluate_model(recc_model, df_test, all_item_ids, K=10, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
